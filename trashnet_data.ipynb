{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a63ee870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import kagglehub\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, datasets, transforms\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f5939e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"feyzazkefe/trashnet\")\n",
    "DATA_DIR = Path('C:/Users/murug/.cache/kagglehub/datasets/feyzazkefe/trashnet/versions/1/dataset-resized')\n",
    "ALL_CLASSES = ['plastic', 'metal', 'glass', 'cardboard', 'paper', 'organic']\n",
    "TRAIN_SPLIT_RATIO = 0.8 # 80% for training, 20% for validation\n",
    "IMAGE_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bd58b999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_dataset_creation(base_dir, classes, num_images_per_class=100):\n",
    "    \"\"\"\n",
    "    Creates a dummy dataset with a similar structure to TrashNet for demonstration.\n",
    "    This function will be skipped if the data directory already exists.\n",
    "    \"\"\"\n",
    "    if base_dir.exists():\n",
    "        print(f\"Dataset already exists at '{base_dir}'. Skipping simulation.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Creating a simulated dataset at '{base_dir}'...\")\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    for cls in classes:\n",
    "        cls_path = base_dir / cls\n",
    "        os.makedirs(cls_path, exist_ok=True)\n",
    "        for i in range(num_images_per_class):\n",
    "            # Create a dummy text file to represent an image\n",
    "            with open(cls_path / f\"image_{i}.txt\", \"w\") as f:\n",
    "                f.write(f\"This is a dummy image for {cls}.\")\n",
    "    print(\"Simulated dataset created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8bab33c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Preparation Logic ---\n",
    "def prepare_data_for_model(data_directory, all_classes):\n",
    "    \"\"\"\n",
    "    Organizes data into train/val splits and returns file paths.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting data preparation from directory: {data_directory} ---\")\n",
    "\n",
    "    if not data_directory.exists():\n",
    "        print(f\"Error: Dataset directory '{data_directory}' not found.\")\n",
    "        print(\"Please download and extract the TrashNet dataset and update the DATA_DIR path.\")\n",
    "        return None, None, None\n",
    "\n",
    "    # Initialize dictionaries to hold file paths\n",
    "    all_files = {cls: [] for cls in all_classes}\n",
    "    valid_classes = []\n",
    "    \n",
    "    for cls in all_classes:\n",
    "        class_path = data_directory / cls\n",
    "        if not class_path.exists():\n",
    "            print(f\"Warning: Directory '{class_path}' not found. Skipping class '{cls}'.\")\n",
    "            continue\n",
    "        \n",
    "        # Only select files that are likely images (ending with common extensions)\n",
    "        files = [f for f in class_path.glob('*') if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']]\n",
    "        \n",
    "        if not files:\n",
    "            print(f\"Warning: No valid image files found in '{class_path}'. Skipping class '{cls}'.\")\n",
    "            continue\n",
    "            \n",
    "        all_files[cls] = files\n",
    "        valid_classes.append(cls)\n",
    "\n",
    "    if not valid_classes:\n",
    "        print(\"\\nError: No valid classes with image data were found. Please check your dataset.\")\n",
    "        return None, None, None\n",
    "        \n",
    "    # Print a summary of the loaded files\n",
    "    print(\"\\nInitial file counts per class (only including classes with data):\")\n",
    "    for cls in valid_classes:\n",
    "        print(f\"  - {cls}: {len(all_files[cls])} images\")\n",
    "    \n",
    "    # --- Split the data into train and validation sets ---\n",
    "    print(\"\\nSplitting data into training and validation sets...\")\n",
    "    train_dir = data_directory.parent / 'train'\n",
    "    val_dir = data_directory.parent / 'validation'\n",
    "    \n",
    "    # Clear existing train/val directories to avoid duplication\n",
    "    if train_dir.exists():\n",
    "        shutil.rmtree(train_dir)\n",
    "    if val_dir.exists():\n",
    "        shutil.rmtree(val_dir)\n",
    "\n",
    "    for cls in valid_classes:\n",
    "        files = all_files[cls]\n",
    "        random.shuffle(files) # Shuffle the files for a good mix\n",
    "        \n",
    "        split_index = int(len(files) * TRAIN_SPLIT_RATIO)\n",
    "        train_files = files[:split_index]\n",
    "        val_files = files[split_index:]\n",
    "        \n",
    "        # Create destination directories\n",
    "        os.makedirs(train_dir / cls, exist_ok=True)\n",
    "        os.makedirs(val_dir / cls, exist_ok=True)\n",
    "        \n",
    "        # Copy files to the new directories\n",
    "        for file in train_files:\n",
    "            shutil.copy(file, train_dir / cls / file.name)\n",
    "        for file in val_files:\n",
    "            shutil.copy(file, val_dir / cls / file.name)\n",
    "    \n",
    "    print(\"\\nData splitting and organization complete!\")\n",
    "\n",
    "    return train_dir, val_dir, valid_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "92944c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Data Preparation Logic ---\n",
    "def prepare_data_for_model(data_directory, classes):\n",
    "    \"\"\"\n",
    "    Organizes data into train/val splits and returns file paths.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting data preparation from directory: {data_directory} ---\")\n",
    "\n",
    "    # Call the simulation function if the data directory is not present\n",
    "    simulate_dataset_creation(data_directory, classes)\n",
    "    \n",
    "    # Initialize dictionaries to hold file paths\n",
    "    all_files = {cls: [] for cls in classes}\n",
    "    for cls in classes:\n",
    "        class_path = data_directory / cls\n",
    "        if not class_path.exists():\n",
    "            print(f\"Warning: Directory '{class_path}' not found. Skipping class '{cls}'.\")\n",
    "            continue\n",
    "        all_files[cls] = [f for f in class_path.glob('*') if f.is_file()]\n",
    "        # Print a summary of the loaded files\n",
    "    print(\"\\nInitial file counts per class:\")\n",
    "    for cls, files in all_files.items():\n",
    "        print(f\"  - {cls}: {len(files)} images\")\n",
    "    \n",
    "    # --- Split the data into train and validation sets ---\n",
    "    print(\"\\nSplitting data into training and validation sets...\")\n",
    "    train_dir = data_directory.parent / 'train'\n",
    "    val_dir = data_directory.parent / 'validation'\n",
    "    \n",
    "    # Clear existing train/val directories to avoid duplication\n",
    "    if train_dir.exists():\n",
    "        shutil.rmtree(train_dir)\n",
    "    if val_dir.exists():\n",
    "        shutil.rmtree(val_dir)\n",
    "\n",
    "    for cls in classes:\n",
    "        files = all_files[cls]\n",
    "        random.shuffle(files) # Shuffle the files for a good mix\n",
    "        \n",
    "        split_index = int(len(files) * TRAIN_SPLIT_RATIO)\n",
    "        train_files = files[:split_index]\n",
    "        val_files = files[split_index:]\n",
    "        \n",
    "        # Create destination directories\n",
    "        os.makedirs(train_dir / cls, exist_ok=True)\n",
    "        os.makedirs(val_dir / cls, exist_ok=True)\n",
    "        \n",
    "        # Copy files to the new directories\n",
    "        for file in train_files:\n",
    "            shutil.copy(file, train_dir / cls / file.name)\n",
    "        for file in val_files:\n",
    "            shutil.copy(file, val_dir / cls / file.name)\n",
    "    \n",
    "    print(\"\\nData splitting and organization complete!\")\n",
    "\n",
    "    return train_dir, val_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "dea02630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_transforms(image_size):\n",
    "    \"\"\"\n",
    "    Defines the image preprocessing and augmentation pipelines.\n",
    "    \"\"\"\n",
    "    # Augmentation for the training set\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Normalization for the validation set (no augmentation)\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    print(\"/nData preprocessing and augmentation pipelines defined.\")\n",
    "    return train_transforms, val_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d913d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Exploratory Data Analysis (EDA) Functions ---\n",
    "def visualize_class_distribution(train_dir, val_dir, classes):\n",
    "    \"\"\"\n",
    "    Creates and displays a bar chart of the class distribution.\n",
    "    \"\"\"\n",
    "    print(\"/nVisualizing class distribution...\")\n",
    "    train_counts = [len(os.listdir(train_dir / cls)) for cls in classes]\n",
    "    val_counts = [len(os.listdir(val_dir / cls)) for cls in classes]\n",
    "    \n",
    "    x = np.arange(len(classes))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    rects1 = ax.bar(x - width/2, train_counts, width, label='Train')\n",
    "    rects2 = ax.bar(x + width/2, val_counts, width, label='Validation')\n",
    "    \n",
    "    ax.set_ylabel('Number of Images')\n",
    "    ax.set_title('Image Count by Class and Split')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(classes, rotation=45, ha=\"right\")\n",
    "    ax.legend()\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "992ed4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_images(data_directory, classes):\n",
    "    \"\"\"\n",
    "    Displays one random image from each class.\n",
    "    \"\"\"\n",
    "    print(\"/nShowing a sample image from each class...\")\n",
    "    fig, axes = plt.subplots(1, len(classes), figsize=(15, 3))\n",
    "    \n",
    "    for i, cls in enumerate(classes):\n",
    "        class_path = data_directory / cls\n",
    "        files = [f for f in class_path.glob('*') if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']]\n",
    "        if files:\n",
    "            sample_file = random.choice(files)\n",
    "            try:\n",
    "                img = Image.open(sample_file)\n",
    "                axes[i].imshow(img)\n",
    "                axes[i].set_title(cls)\n",
    "                axes[i].axis('off')\n",
    "            except Exception as e:\n",
    "                axes[i].set_title(f\"{cls} (Error)\")\n",
    "                axes[i].axis('off')\n",
    "                print(f\"Could not open image file {sample_file}: {e}\")\n",
    "        else:\n",
    "            axes[i].set_title(f\"{cls} (No images)\")\n",
    "            axes[i].axis('off')\n",
    "            \n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b4ac353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pixel_distribution(data_directory, classes):\n",
    "    \"\"\"\n",
    "    Analyzes and plots the pixel intensity distribution for a sample of images.\n",
    "    \"\"\"\n",
    "    print(\"/nAnalyzing pixel intensity distribution...\")\n",
    "    num_samples = 5 # Number of images to sample from each class for analysis\n",
    "    all_pixels = {'R': [], 'G': [], 'B': []}\n",
    "    \n",
    "    for cls in classes:\n",
    "        class_path = data_directory / cls\n",
    "        files = list(class_path.glob('*'))\n",
    "        if not files:\n",
    "            continue\n",
    "            \n",
    "        sampled_files = random.sample(files, min(num_samples, len(files)))\n",
    "        \n",
    "        for file in sampled_files:\n",
    "            try:\n",
    "                img = Image.open(file).convert('RGB')\n",
    "                img_array = np.array(img)\n",
    "                all_pixels['R'].extend(img_array[:, :, 0].flatten())\n",
    "                all_pixels['G'].extend(img_array[:, :, 1].flatten())\n",
    "                all_pixels['B'].extend(img_array[:, :, 2].flatten())\n",
    "            except Exception as e:\n",
    "                print(f\"Could not process image {file}: {e}\")\n",
    "                \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    axes[0].hist(all_pixels['R'], bins=256, color='red', alpha=0.7)\n",
    "    axes[0].set_title('Red Channel')\n",
    "    axes[1].hist(all_pixels['G'], bins=256, color='green', alpha=0.7)\n",
    "    axes[1].set_title('Green Channel')\n",
    "    axes[2].hist(all_pixels['B'], bins=256, color='blue', alpha=0.7)\n",
    "    axes[2].set_title('Blue Channel')\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.set_xlabel('Pixel Intensity')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        \n",
    "    fig.suptitle('Pixel Intensity Distribution Across All Classes')\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d0bb444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_class_distribution(train_dir, val_dir, classes):\n",
    "    \"\"\"\n",
    "    Creates and displays a bar chart of the class distribution.\n",
    "    \"\"\"\n",
    "    print(\"\\nVisualizing class distribution...\")\n",
    "    train_counts = [len(os.listdir(train_dir / cls)) for cls in classes]\n",
    "    val_counts = [len(os.listdir(val_dir / cls)) for cls in classes]\n",
    "    \n",
    "    x = np.arange(len(classes))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    rects1 = ax.bar(x - width/2, train_counts, width, label='Train')\n",
    "    rects2 = ax.bar(x + width/2, val_counts, width, label='Validation')\n",
    "    \n",
    "    ax.set_ylabel('Number of Images')\n",
    "    ax.set_title('Image Count by Class and Split')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(classes, rotation=45, ha=\"right\")\n",
    "    ax.legend()\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e8eca9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('C:/Users/murug/.cache/kagglehub/datasets/feyzazkefe/trashnet/versions/1')\n",
    "NUM_CLASSES = 6\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "MODEL_NAME = \"resnet50\" # Options: resnet50, mobilenet_v2, efficientnet_b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cf52a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading ---\n",
    "def get_data_loaders(data_root, image_size, batch_size):\n",
    "    \"\"\"\n",
    "    Creates data loaders for the training and validation sets.\n",
    "    \"\"\"\n",
    "    print(\"\\nLoading data from prepared directories...\")\n",
    "    # These transforms should match the ones used in the data prep script for validation\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'validation': transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    \n",
    "    image_datasets = {\n",
    "        x: datasets.ImageFolder(\n",
    "            os.path.join(data_root, x), \n",
    "            data_transforms[x]\n",
    "        ) for x in ['train', 'validation']\n",
    "    }\n",
    "    \n",
    "    dataloaders = {\n",
    "        x: DataLoader(\n",
    "            image_datasets[x], \n",
    "            batch_size=batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=4\n",
    "        ) for x in ['train', 'validation']\n",
    "    }\n",
    "    \n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'validation']}\n",
    "    class_names = image_datasets['train'].classes\n",
    "    \n",
    "    print(\"Data loaders created successfully.\")\n",
    "    return dataloaders, dataset_sizes, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "732fc8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Development (Transfer Learning) ---\n",
    "def build_model(model_name, num_classes):\n",
    "    \"\"\"\n",
    "    Loads a pre-trained model, freezes base layers, and adds a custom classifier.\n",
    "    \"\"\"\n",
    "    print(f\"\\nBuilding model with {model_name}...\")\n",
    "    if model_name == \"resnet50\":\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        # Freeze all layers in the pre-trained model\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Replace the final fully connected layer\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    elif model_name == \"mobilenet_v2\":\n",
    "        model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        num_ftrs = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "    elif model_name == \"efficientnet_b0\":\n",
    "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        num_ftrs = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model name.\")\n",
    "\n",
    "    print(\"Model built successfully with a custom classifier.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e4ad98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training and Validation Loop ---\n",
    "def train_model(model, dataloaders, dataset_sizes, num_epochs, learning_rate):\n",
    "    \"\"\"\n",
    "    The main function for training and validating the model.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
    "    \n",
    "    print(\"\\nStarting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train() # Set model to training mode\n",
    "            else:\n",
    "                model.eval() # Set model to evaluate mode\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # Iterate over data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # Backward pass and optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    print(\"\\nTraining complete!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b7cc825c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting data preparation from directory: C:\\Users\\murug\\.cache\\kagglehub\\datasets\\feyzazkefe\\trashnet\\versions\\1\\dataset-resized ---\n",
      "Dataset already exists at 'C:\\Users\\murug\\.cache\\kagglehub\\datasets\\feyzazkefe\\trashnet\\versions\\1\\dataset-resized'. Skipping simulation.\n",
      "Warning: Directory 'C:\\Users\\murug\\.cache\\kagglehub\\datasets\\feyzazkefe\\trashnet\\versions\\1\\dataset-resized\\organic' not found. Skipping class 'organic'.\n",
      "\n",
      "Initial file counts per class:\n",
      "  - plastic: 482 images\n",
      "  - metal: 410 images\n",
      "  - glass: 501 images\n",
      "  - cardboard: 403 images\n",
      "  - paper: 594 images\n",
      "  - organic: 0 images\n",
      "\n",
      "Splitting data into training and validation sets...\n",
      "\n",
      "Data splitting and organization complete!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[166]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# --- Script Execution ---\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     train_data_path, val_data_path, valid_classes = prepare_data_for_model(DATA_DIR, ALL_CLASSES)\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m train_data_path \u001b[38;5;129;01mand\u001b[39;00m val_data_path \u001b[38;5;129;01mand\u001b[39;00m valid_classes:\n\u001b[32m     27\u001b[39m         train_transforms, val_transforms = define_transforms(IMAGE_SIZE)\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "def print_final_summary(train_dir, val_dir, classes):\n",
    "    \"\"\"\n",
    "    Prints the final file counts for the train and validation sets.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Final Data Summary ---\")\n",
    "    print(f\"\\nTraining set located at: {train_dir}\")\n",
    "    for cls in classes:\n",
    "        count = len(os.listdir(train_dir / cls))\n",
    "        print(f\"  - {cls}: {count} images\")\n",
    "\n",
    "    print(f\"\\nValidation set located at: {val_dir}\")\n",
    "    for cls in classes:\n",
    "        count = len(os.listdir(val_dir / cls))\n",
    "        print(f\"  - {cls}: {count} images\")\n",
    "    \n",
    "    print(\"\\n--- Next Steps for Class Imbalance ---\")\n",
    "    print(\"If you notice a significant class imbalance in the visualization, you can address it during the training process by:\")\n",
    "    print(\"  - Using class weights in your loss function.\")\n",
    "    print(\"  - Applying data augmentation techniques to the minority classes more aggressively.\")\n",
    "    print(\"  - Using a different sampling strategy, such as oversampling the minority class.\")\n",
    "    print(\"\\nData is now ready for model training!\")\n",
    "\n",
    "# --- Script Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    train_data_path, val_data_path, valid_classes = prepare_data_for_model(DATA_DIR, ALL_CLASSES)\n",
    "    if train_data_path and val_data_path and valid_classes:\n",
    "        train_transforms, val_transforms = define_transforms(IMAGE_SIZE)\n",
    "        visualize_class_distribution(train_data_path, val_data_path, valid_classes)\n",
    "        show_sample_images(train_data_path, val_data_path, valid_classes)\n",
    "        analyze_pixel_distribution(train_data_path, val_data_path, valid_classes)\n",
    "        print_final_summary(train_data_path, val_data_path, valid_classes)\n",
    "    else:\n",
    "        print(\"\\nSkipping further processing due to data preparation errors. Please resolve the issues above.\")\n",
    "\n",
    "    try:\n",
    "        dataloaders, dataset_sizes, class_names = get_data_loaders(DATA_ROOT, IMAGE_SIZE, BATCH_SIZE)\n",
    "        model_ft = build_model(MODEL_NAME, NUM_CLASSES)\n",
    "        model_ft = train_model(model_ft, dataloaders, dataset_sizes, NUM_EPOCHS, LEARNING_RATE)\n",
    "        # You can now save the trained model for later use\n",
    "        # torch.save(model_ft.state_dict(), 'trashnet_model.pth')\n",
    "        print(f\"\\nModel training finished. Final model has {NUM_CLASSES} output classes.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cc2633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking original directory: C:\\Users\\murug\\.cache\\kagglehub\\datasets\\feyzazkefe\\trashnet\\versions\\1\\organic\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\murug\\\\.cache\\\\kagglehub\\\\datasets\\\\feyzazkefe\\\\trashnet\\\\versions\\\\1\\\\organic'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Check the contents of the original 'organic' folder\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mChecking original directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_DIR\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33morganic\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m original_files = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43morganic\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFiles found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(original_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Check the contents of the new 'train/organic' folder\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\murug\\\\.cache\\\\kagglehub\\\\datasets\\\\feyzazkefe\\\\trashnet\\\\versions\\\\1\\\\organic'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set this to the path where your original dataset is located\n",
    "DATA_DIR = Path('C:/Users/murug/.cache/kagglehub/datasets/feyzazkefe/trashnet/versions/1')\n",
    "\n",
    "# Check the contents of the original 'organic' folder\n",
    "print(f\"Checking original directory: {DATA_DIR / 'organic'}\")\n",
    "original_files = os.listdir(DATA_DIR / 'organic')\n",
    "print(f\"Files found: {len(original_files)}\")\n",
    "\n",
    "# Check the contents of the new 'train/organic' folder\n",
    "TRAIN_DIR = DATA_DIR.parent / 'train'\n",
    "print(f\"Checking training directory: {TRAIN_DIR / 'organic'}\")\n",
    "train_files = os.listdir(TRAIN_DIR / 'organic')\n",
    "print(f\"Files found: {len(train_files)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
